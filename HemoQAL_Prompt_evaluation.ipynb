{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGpB7Qu2n1t1",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0736a342-4569-4bce-f5f6-4b00b43b895e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q openai tiktoken langchain langchain-community langchain-core magic_timer unstructured pydantic rouge_score==0.1.2 evaluate==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from magic_timer import MagicTimer\n",
        "\n",
        "import openai\n",
        "import tiktoken\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "MODEL_NAME = \"gpt-4o-2024-05-13\""
      ],
      "metadata": {
        "id": "27Bj59sqUYPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/LLM - 22h + UFBA  + ğŸ‡©ğŸ‡ª/code_cronicas_rag/questions_answers_final.xlsx\""
      ],
      "metadata": {
        "id": "H-GNFWxXWZ_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_questions_answer = pd.read_excel(path).filter([\"question\", \"answer\"])\n",
        "df_questions_answer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "1mOudnidW8Te",
        "outputId": "f08bb764-16e4-4417-dacb-13b8a8e69213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What effect does the global sialyltransferase ...   \n",
              "1  What is required as a prerequisite for the dev...   \n",
              "2  What is the main focus of the model analyzed i...   \n",
              "3  What is used to monitor and adjust intravenous...   \n",
              "4  What is a deletion hotspot in the context of t...   \n",
              "\n",
              "                                              answer  \n",
              "0  In vivo inhibition of sialylation with the glo...  \n",
              "1  Further studies of genetic markers are require...  \n",
              "2  The main focus of the model analyzed in the do...  \n",
              "3                                      Anti-Xa level  \n",
              "4  The poly(T)â€track in F8 intron 13 (c.2113+449_...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b47f5c69-2027-4b04-8c27-c9064e3d6cf4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What effect does the global sialyltransferase ...</td>\n",
              "      <td>In vivo inhibition of sialylation with the glo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is required as a prerequisite for the dev...</td>\n",
              "      <td>Further studies of genetic markers are require...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the main focus of the model analyzed i...</td>\n",
              "      <td>The main focus of the model analyzed in the do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is used to monitor and adjust intravenous...</td>\n",
              "      <td>Anti-Xa level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is a deletion hotspot in the context of t...</td>\n",
              "      <td>The poly(T)â€track in F8 intron 13 (c.2113+449_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b47f5c69-2027-4b04-8c27-c9064e3d6cf4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b47f5c69-2027-4b04-8c27-c9064e3d6cf4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b47f5c69-2027-4b04-8c27-c9064e3d6cf4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bef21a86-596e-4c31-b4c7-9287197cb8f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bef21a86-596e-4c31-b4c7-9287197cb8f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bef21a86-596e-4c31-b4c7-9287197cb8f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_questions_answer",
              "summary": "{\n  \"name\": \"df_questions_answer\",\n  \"rows\": 93,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"What is the general outcome of post-operative treatment in haemophilic knee arthropathy?\",\n          \"What system is activated in PWH that indicates increased osteoclastic activity?\",\n          \"What is the potential effect of danger signals from bleeding on the anti-FVIII antibody response?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 91,\n        \"samples\": [\n          \"The post-operative outcome in haemophilic knee arthropathy may not be as good as the outcomes seen in regular cases but there is significant improvement in functional outcome and quality of life.\",\n          \"The RANKL/OPG system.\",\n          \"The potential effect of danger signals from bleeding on the anti-FVIII antibody response is an increased risk of inhibitor development.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai(model=None, prompt=None, history=None, params=None, sys_prompt=None):\n",
        "    if model is None:\n",
        "        return \"Precisa passar o modelo openIA\"\n",
        "    else:\n",
        "        default_kwargs = dict(model=model)\n",
        "\n",
        "        if params:\n",
        "            params = {**default_kwargs, **params}\n",
        "        else:\n",
        "            params = default_kwargs\n",
        "\n",
        "        if history is None:\n",
        "            history=[\n",
        "                {'role':'system', 'content':sys_prompt},\n",
        "                {'role':'user', 'content':prompt}\n",
        "                ]\n",
        "        else:\n",
        "            history.append({'role':'user', 'content':prompt})\n",
        "\n",
        "\n",
        "        response = openai.chat.completions.create(\n",
        "            **params,\n",
        "            messages=history,\n",
        "            )\n",
        "\n",
        "        usage = {\n",
        "            \"prompt_tokens\":response.usage.prompt_tokens,\n",
        "            \"output_tokens\":response.usage.completion_tokens,\n",
        "            \"total_tokens\":response.usage.total_tokens,\n",
        "        }\n",
        "\n",
        "        output_model = response.choices[0].message.content\n",
        "        history.append({\"role\":\"assistant\", \"content\":output_model})\n",
        "\n",
        "        return usage, history, output_model"
      ],
      "metadata": {
        "id": "PPpL4utWZ_rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_system_prompt = \"\"\"You always respond in American English.\n",
        "Your role is as an expert in validating questions in the healthcare field\n",
        "\"\"\"\n",
        "\n",
        "evaluate_question_prompt = \"\"\"You will receive a question about the healthcare field, using your expert knowledge, evaluate the quality of the question. Use the following score:\n",
        "\n",
        "0: The question doesn't make sense to you or is poorly formulated.\n",
        "1: The question makes sense but seems specific to some work or project.\n",
        "2: The question makes sense and can be answered by a specialist with knowledge of the subject.\n",
        "3: The question makes sense and can be answered by a specialist but is outside of your area of expertise.\n",
        "\n",
        "Example:\n",
        "Question: How many people with hemophilia are associated with adulthood?\n",
        "Score: 0\n",
        "Question: What types of hemophilia are presented in the study?\n",
        "Score: 1\n",
        "Question: What types of hemophilia are currently known?\n",
        "Score: 2\n",
        "Question: How many goals has Italy scored in World Cup matches?\n",
        "Score: 3\n",
        "\n",
        "The output must still be json with the characteristics of the following example:\n",
        "Very calmly, make sure that the json does not contain errors.\n",
        "Check and make sure there are no errors when loading this json in `json.loads` python code.\n",
        "\n",
        "```\n",
        "[\n",
        "{{\n",
        "\"question_score\": \"Answer with 0, 1, 2 or 3 accordingly\"\n",
        "}},\n",
        "]\n",
        "```\n",
        "\n",
        "Question: {question}\n",
        "Score:\n",
        "\n",
        "# The output must only be the file (json) without errors, it is very important that there are no errors when loaded by python's `json.loads`.\n",
        "\"\"\"\n",
        "\n",
        "create_openai_kwargs = {\n",
        "    \"response_format\": {\"type\": \"json_object\"},\n",
        "    \"seed\":341,\n",
        "    \"temperature\":0,\n",
        "}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ttz1i1XuYtaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_score = []\n",
        "for question in df_questions_answer[\"question\"]:\n",
        "\n",
        "  _, _, create_out = call_openai(\n",
        "    model=MODEL_NAME,\n",
        "    prompt=evaluate_question_prompt.format(question=question),\n",
        "    history=None,\n",
        "    params=create_openai_kwargs,\n",
        "    sys_prompt = create_system_prompt\n",
        "  )\n",
        "\n",
        "  try:\n",
        "      sample = json.loads(create_out)\n",
        "      print(\"json ok\")\n",
        "  except:\n",
        "      print(f\"\\tERROR\")\n",
        "  else:\n",
        "      sample[\"question\"] = question\n",
        "      questions_score.append(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fb6cFMJcdfbC",
        "outputId": "1e34367d-b322-48e4-82ff-b2e896328af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_question_score = pd.DataFrame(questions_score)"
      ],
      "metadata": {
        "id": "UW4H-lfje89l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_question_score[\"question_score\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhs9ZhtekM8x",
        "outputId": "bbbf7e21-4acd-4560-debb-110674b47127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question_score\n",
              "2    84\n",
              "1     8\n",
              "0     1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "J7mQmV9FgRm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_system_prompt = \"\"\"You always respond in American English.\n",
        "Your role is as a specialist in validating question and answer pairs in the healthcare field\n",
        "\"\"\"\n",
        "\n",
        "evaluate_question_answer_prompt = \"\"\"You will receive a question and an answer about the healthcare field, using your specialized knowledge, evaluate the pair by answering the following three questions:\n",
        "\n",
        "Is the answer correct? (Does it answer the question, yes or no)\n",
        "Is the answer incomplete? (It answers the question, but as a specialist, you would expect other pertinent information to answer the question, yes or no)\n",
        "Is the answer concise and direct? (Does it answer only what was asked, yes or no)\n",
        "\n",
        "\n",
        "The output must still be json with the characteristics of the following example:\n",
        "Very calmly, make sure that the json does not contain errors.\n",
        "Check and make sure there are no errors when loading this json in `json.loads` python code.\n",
        "\n",
        "```\n",
        "[\n",
        "{{\n",
        "\"Is the answer correct?\": \"Answer with yes or no here\",\n",
        "\"Is the answer incomplete?\": \"Answer with yes or no here\",\n",
        "\"Is the answer concise and direct?\": \"Answer with yes or no here\"\n",
        "}},\n",
        "]\n",
        "```\n",
        "\n",
        "Question: {question}\n",
        "Answer: {answer}\n",
        "The output must only be the file (json) without errors, it is very important that there are no errors when loaded by python's `json.loads`.\n",
        "\"\"\"\n",
        "\n",
        "create_openai_kwargs = {\n",
        "    \"response_format\": {\"type\": \"json_object\"},\n",
        "    \"seed\":341,\n",
        "    \"temperature\":0,\n",
        "}\n"
      ],
      "metadata": {
        "id": "CLyQdN5kaXB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pair_score = []\n",
        "for idx, (question, answer) in df_questions_answer.iterrows():\n",
        "\n",
        "  _, _, create_out = call_openai(\n",
        "    model=MODEL_NAME,\n",
        "    prompt=evaluate_question_answer_prompt.format(question=question, answer=answer),\n",
        "    history=None,\n",
        "    params=create_openai_kwargs,\n",
        "    sys_prompt = create_system_prompt\n",
        "  )\n",
        "\n",
        "  try:\n",
        "      sample = json.loads(create_out)\n",
        "      print(\"json ok\")\n",
        "  except:\n",
        "      print(f\"\\tERROR\")\n",
        "  else:\n",
        "      sample[\"question\"] = question\n",
        "      pair_score.append(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jpPa5-gsaBz3",
        "outputId": "66af2053-5fbc-4d42-9e83-17f689f72bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n",
            "json ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pair_score = pd.DataFrame(pair_score)"
      ],
      "metadata": {
        "id": "2FeFrNg8hvy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# juntando os doin e cruzando por question"
      ],
      "metadata": {
        "id": "259aiyPgiuhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    df_pair_score.merge(df_question_score, on=\"question\")\n",
        "                 .rename(\n",
        "                    columns = {\n",
        "                        \"Is the answer correct?\": \"A resposta responde Ã  pergunta?\",\n",
        "                        \"Is the answer incomplete?\": \"A resposta estÃ¡ Incompleta?\",\n",
        "                        \"Is the answer concise and direct?\": \"A resposta e concisa e direta?\",\n",
        "                        \"question_score\":\"model_question_score\",\n",
        "                        \"question\":\"QuestÃµes\"\n",
        "                    }\n",
        "                  )\n",
        "                 .filter([\"QuestÃµes\",\n",
        "                          \"model_question_score\",\n",
        "                          \"A resposta responde Ã  pergunta?\",\n",
        "                          \"A resposta estÃ¡ Incompleta?\",\n",
        "                          \"A resposta e concisa e direta?\"\n",
        "                 ])\n",
        "                 .to_csv(\"/content/drive/MyDrive/LLM - 22h + UFBA  + ğŸ‡©ğŸ‡ª/code_cronicas_rag/model_analysis.csv\", index = False)\n",
        ")"
      ],
      "metadata": {
        "id": "d90XHL-Hk9f1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}